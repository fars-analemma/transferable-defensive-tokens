Summary
StruQ addresses the problem of prompt injection attacks in LLM-integrated applications, an issue OWASP highlights as the top security risk for LLMs. To counteract these attacks, we introduce and rely on structured queries, which separate LLM prompts from data. Building on this concept, we introduce StruQ, a way to build LLMs that can answer structured queries. StruQ models utilize structured instruction tuninga modified version of instruction tuning -to convert noninstruction-tuned models to defended instruction-tuned models. Then, a front-end converts prompts and data to structured queries that are passed to the model. Our experiments show our models are secure against a wide class of adaptive and non-adaptive human-crafted prompt injections, and improve security against optimization-based attacks, with minimal impact on model utility. This suggests that structured queries are a promising direction for protecting LLM-integrated applications from prompt injections, and we hope it will inspire further research on better ways to train LLMs that can answer structured queries.