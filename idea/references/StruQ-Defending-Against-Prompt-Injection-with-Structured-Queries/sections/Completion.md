Completion
-Real fake response with real / close / other delimiters -Close -Other ~\cite{b29} -RealCmb Completion + Ignore + Escape-Separation -OtherCmb Others HackAPrompt ~\cite{b40} human-crafted TAP ~\cite{b16} LLM-crafted GCG ~\cite{b17} gradient-guided 3 Prompt Injection Attacks

Section references:
[b16]: Anay Mehrotra, Manolis Zampetakis, Paul Kassianik, Blaine Nelson, Hyrum Anderson, Yaron Singer, Amin Karbasi. Tree of attacks: Jailbreaking black-box LLMs automatically. (2023). Tree of attacks: Jailbreaking black-box LLMs automatically
[b17]: Andy Zou, Zifan Wang, J Kolter, Matt Fredrikson. Universal and transferable adversarial attacks on aligned language models. (2023). Universal and transferable adversarial attacks on aligned language models
[b29]: Simon Willison. Delimiters won't save you from prompt injection. (2023). Delimiters won't save you from prompt injection
[b40]: Sander Schulhoff, Jeremy Pinto, Anaum Khan, Louis-Fran√ßois Bouchard, Chenglei Si, Svetlina Anati, Valen Tagliabue, Anson Kost, Christopher Carnahan, Jordan Boyd-Graber. Ignore this title and hackaprompt: Exposing systemic vulnerabilities of llms through a global scale prompt hacking competition. (2023). Ignore this title and hackaprompt: Exposing systemic vulnerabilities of llms through a global scale prompt hacking competition