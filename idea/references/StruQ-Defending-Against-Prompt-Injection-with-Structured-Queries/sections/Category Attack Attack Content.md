Category Attack Attack Content
Ignore Naïve ~\cite{b57} (none) Ignore ~\cite{b8} "Ignore previous ..." Escape -Deletion ~\cite{b58} '\b' or '\r' -Separation ~\cite{b5} '\n' or '\t'

Section references:
[b5]: Yupei Liu, Yuqi Jia, Runpeng Geng, Jinyuan Jia, Neil Zhenqiang. Formalizing and benchmarking prompt injection attacks and defenses. (2024). USENIX Security Symposium
[b57]: Rich Harang. Securing LLM Systems Against Prompt Injection. (2023). Securing LLM Systems Against Prompt Injection
[b58]: Mark Breitenbach, Adrian Wood, Win Suen, Po-Ning Tseng. Dont you (forget nlp): Prompt injection with control characters in chatgpt. (2023). Dont you (forget nlp): Prompt injection with control characters in chatgpt
[b8]: Fábio Perez, Ian Ribeiro. Ignore previous prompt: Attack techniques for language models. (2022). NeurIPS ML Safety Workshop