4.6.1 Detection-based Defenses
Detection-based approaches aim to identify adversarial prompts before generation. Some methods monitor internal forward-pass signals to detect injected instructions such as attention drift (AttentionTracker~\cite{}) activation shifts (TaskTracker~\cite{}) and uncertainty under masking (UniGuardian~\cite{}). Earlier baselines rely on perplexity spikes or likelihood anomalies ~\cite{}. Other works treat detection as a classification problem using LLM-based judges (SelfDefend~\cite{}) lightweight classifiers (Prompt-Guard~\cite{} JailGuard~\cite{}) or adversarially optimized detectors (DataSentinel~\cite{}). A growing body of benchmarks—including PINT~\cite{} GenTel-Safe~\cite{} BIPIA~\cite{} ToolHijacker~\cite{} and JailbreakBench~\cite{}—provides standardized test suites for evaluation. While detection-based defenses can flag suspicious prompts they operate outside the generation process and offer no guarantee of safe behavior at inference. As such they serve as a valuable complement to finetuning-based defenses like DRIP which directly enhance the model’s semantic awareness and role disentanglement during generation.