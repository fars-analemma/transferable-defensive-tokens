4.5.4 Future Work
Model scale. All experiments in this work are conducted on open-source models in the 7B–8B parameter range (LLaMA-8B and Mistral-7B) primarily due to computational and training resource constraints. While these models provide a reasonable testbed for controlled comparisons the absolute robustness and generalization capabilities may differ when scaled to larger backbones (e.g. 13B or 34B). Extending our approach to larger model scales is a natural next step and may also reveal whether our architectural and supervision strategies generalize under increased capacity and complexity.
 Single-turn vs. multi-turn. Our current framework is designed and evaluated in single-turn settings where each prompt is processed independently without conversational history. While this setup simplifies analysis and attribution many real-world applications of LLMs (e.g. chat assistants autonomous agents) require multi-turn reasoning and memory ~\cite{}. Extending our approach to multi-turn dialogue will likely require additional mechanisms for instruction aggregation such as cross-turn fusion pathways to robustly maintain long-term instruction alignment in the presence of injected distractions.
 Attack beyond text modality. Our evaluation focuses primarily on prompt injection attacks in text-only settings. While we include both heuristic and optimization-based attacks as well as agent-based scenarios (InjecAgent) we do not evaluate multi-modal prompt injection—such as those targeting vision-language models~\cite{}. Exploring these cross-modal attack surfaces remains an important direction for future work.