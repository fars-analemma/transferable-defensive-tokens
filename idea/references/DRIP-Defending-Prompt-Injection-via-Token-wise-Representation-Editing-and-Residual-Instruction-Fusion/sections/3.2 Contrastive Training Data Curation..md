3.2 Contrastive Training Data Curation.
To enforce such gradient constraints we curate a training dataset from the SEP training split ~\cite{} which provides 10k tuples (task injected_task data response). The top-level tasks are drawn from SQuAD ~\cite{} while the injected tasks originate from Alpaca ~\cite{}. Due to this mismatch Case 3 (as defined in Definition 3.1[ref_id]A3.EGx2) is not represented. To address this we discard the original injected tasks and resample new ones from SQuAD matching the distribution of the top-level tasks. This adjustment ensures that identical instruction strings may appear both legitimately as top-level directives and deceptively as embedded data.
 To generate the ground-truth responses we build a curation pipeline as shown in Figure 4. Each DPO pair consists of a preferred response and a rejected response. The preferred response is Case1 and the rejected response is Case2 as defined in Equation 3.1[ref_id]A3.EGx2. If there exists another DPO pair in the training set where x_{a} serves as instruction this preferred response then corresponds to Case3 in Equation 3.1[ref_id]A3.EGx2. All ground-truth responses are generated by querying GPT-4o~\cite{} with the prompt in Figure 11[ref_id]A3.F11.
 However since GPT models are themselves vulnerable to prompt injection blindly trusting their responses can introduce noise. Moreover GPT’s own defenses may over-suppress the data semantics of x_{a} in Case1 thereby degrading the utility of ground-truths. We therefore adopt two complementary data sanitization strategies for response integrity and response utility.
 •
 Response integrity. We apply an XML-tagging strategy~\cite{} enclosing the data section D within special tags <start of data> ... <end of data>. In addition we introduce a separate response auditing step using an LLM-as-judge~\cite{} (prompt is detailed in Figure 12[ref_id]A3.F12). This auditor classifies the injected instruction as “Executed” “Rejected” or “Not Detected”. Examples labeled as “Executed” are regenerated until the injected task is treated purely as data.
 •
 Response utility. To prevent over-defensive behavior from discarding useful information we include a meta-instruction: “Do not omit or skip any sentence phrase number punctuation or word” in the prompt. This encourages the model to leverage the entire data section.
[IMAGE START] [IMAGE URL: /mnt/bmcpfs-29000zjpjtl6xjmjiifyk/xkhu/ideation_workspace/papers/reference_figures/79965ee7e90abc32a6cbc0ff06caf58f.png] Figure 4: Data curation pipeline.
One DPO pair generates a preferred and a rejected response.
The first step generates the ground-truth response by querying the LLM.
The second step is an LLM-as-judge to verify that the injected task is not executed.
The two steps iteratively refine the response until the preferred response is correct.
Note that only the preferred response needs to go through the extra auditing.[IMAGE END]
