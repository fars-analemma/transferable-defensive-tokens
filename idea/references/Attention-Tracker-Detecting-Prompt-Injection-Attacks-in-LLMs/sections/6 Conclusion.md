6 Conclusion
In this paper we conducted a comprehensive analysis of prompt injection attacks on LLMs uncovering the distraction effect and its impact on attention mechanisms. Our proposed detection method \attn significantly outperforms existing baselines demonstrating high effectiveness even when utilizing small LLMs. The discovery of the distraction effect and the detection method provides a new perspective on prompt injection attacks and lays the groundwork for future defenses. Additionally it enhances understanding of LLM mechanisms potentially improving model reliability and robustness.