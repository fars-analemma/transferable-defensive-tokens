Attention Mechanism of LLM.
As we have seen the increasing deployment of LLMs in everyday life understanding their underlying working mechanisms is crucial. Several recent works ~\cite{bib.bib34 bib.bib11 bib.bib45} have sought to explain how various components in LLMs contribute to their outputs particularly the role of attention mechanisms. Studies indicate that different attention heads in LLMs have distinct functionalities. Induction heads ~\cite{bib.bib25 bib.bib7} specialize in in-context learning capturing patterns within input data while successor heads ~\cite{bib.bib12} handle incrementing tokens in natural sequences like numbers or days. Additionally a small subset of heads represent input-output functions as “function vectors” ~\cite{bib.bib38} with strong causal effects in middle layers enabling complex tasks. There is also research exploring the use of attention to manipulate models. For instance ~\cite{bib.bib44} proposes controlling model behavior by adjusting attention scores to enforce specific output formats. Other works that leverage attention to detect LLM behavior include Lookback Lens~\cite{bib.bib6} which detects and mitigates contextual hallucinations and AttenTD~\cite{bib.bib22} which identifies trojan attacks. In this work we identify the distraction effect of LLM in the important heads under prompt injection attacks and detect these attacks based on the observed effects.


## Section References
[bib.bib34] Singh et al. (2024) Chandan Singh Jeevana Priya Inala Michel Galley Rich Caruana and Jianfeng Gao. 2024. Rethinking interpretability in the era of large language models. arXiv preprint arXiv:2402.01761.
[bib.bib11] Ferrando et al. (2024) Javier Ferrando Gabriele Sarti Arianna Bisazza and Marta R Costa-jussà. 2024. A primer on the inner workings of transformer-based language models. arXiv preprint arXiv:2405.00208.
[bib.bib45] Zhao et al. (2024) Haiyan Zhao Hanjie Chen Fan Yang Ninghao Liu Huiqi Deng Hengyi Cai Shuaiqiang Wang Dawei Yin and Mengnan Du. 2024. Explainability for large language models: A survey. ACM Transactions on Intelligent Systems and Technology 15(2):1–38.
[bib.bib25] Olsson et al. (2022) Catherine Olsson Nelson Elhage Neel Nanda Nicholas Joseph Nova DasSarma Tom Henighan Ben Mann Amanda Askell Yuntao Bai Anna Chen et al. 2022. In-context learning and induction heads. arXiv preprint arXiv:2209.11895.
[bib.bib7] Crosbie and Shutova (2024) J. Crosbie and E. Shutova. 2024. Induction heads as an essential mechanism for pattern matching in in-context learning [https://arxiv.org/abs/2407.07011]. Preprint arXiv:2407.07011.
[bib.bib12] Gould et al. (2024) Rhys Gould Euan Ong George Ogden and Arthur Conmy. 2024. Successor heads: Recurring interpretable attention heads in the wild [https://openreview.net/forum?id=kvcbV8KQsi]. In The Twelfth International Conference on Learning Representations.
[bib.bib38] Todd et al. (2024) Eric Todd Millicent Li Arnab Sen Sharma Aaron Mueller Byron C Wallace and David Bau. 2024. Function vectors in large language models [https://openreview.net/forum?id=AwyxtyMwaG]. In The Twelfth International Conference on Learning Representations.
[bib.bib44] Zhang et al. (2024b) Qingru Zhang Chandan Singh Liyuan Liu Xiaodong Liu Bin Yu Jianfeng Gao and Tuo Zhao. 2024b. Tell your model where to attend: Post-hoc attention steering for LLMs [https://openreview.net/forum?id=xZDWO0oejD]. In The Twelfth International Conference on Learning Representations.
[bib.bib6] Chuang et al. (2024) Yung-Sung Chuang Linlu Qiu Cheng-Yu Hsieh Ranjay Krishna Yoon Kim and James Glass. 2024. Lookback lens: Detecting and mitigating contextual hallucinations in large language models using only attention maps [https://arxiv.org/abs/2407.07071]. Preprint arXiv:2407.07071.
[bib.bib22] Lyu et al. (2022) Weimin Lyu Songzhu Zheng Tengfei Ma and Chao Chen. 2022. A study of the attention abnormality in trojaned BERTs [https://doi.org/10.18653/v1/2022.naacl-main.348]. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies pages 4727–4741 Seattle United States. Association for Computational Linguistics.