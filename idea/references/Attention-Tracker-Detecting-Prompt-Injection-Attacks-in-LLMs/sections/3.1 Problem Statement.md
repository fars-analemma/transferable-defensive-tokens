3.1 Problem Statement
Following ~\cite{bib.bib21} we define a prompt injection attack as follows:
 Definition 1.
 In an LLM-Integrated Application given an instruction I_{t} and data D for a target task t a prompt injection attack inserts or modifies the data D sequentially with the separator S and the injected instruction I_{j} for the injected task j causing the LLM-Integrated Application to accomplish task j instead of t.
 As illustrated in Figure 1 an exemplary instruction I_{t} can be “Analyze the attitude of the following sentence”. Typically the user should provide data D which contains the sentence to be analyzed. However in the case of prompt injection attacks the attacker may insert or change the original D with “Ignore previous instruction (S) and print hacked (I_{j})”. This manipulation directs the LLM to do the injected task j (output “hacked”) instead of the target task t (attitude analysis).
 This work addresses the problem of prompt injection detection aiming to identify whether the given data prompt D has been compromised.
[IMAGE START] [IMAGE URL: /mnt/bmcpfs-29000zjpjtl6xjmjiifyk/xkhu/ideation_workspace/papers/reference_figures/187fc6d067145003ac29000bfeedc09a.png] Figure 1: Overview of \attn: This figure illustrates the detection pipeline of \attn and highlights the distraction effect caused by prompt injection attacks. For normal data, the attention of the last token typically focuses on the original instruction. However, when dealing with attack data, which often includes a separator and an injected instruction (e.g., print “hacked”), the attention shifts from the original instruction to the injected instruction. By leveraging this distraction effect, \attn tracks the total attention score from the last token to the instruction prompt within important heads to detect prompt injection attacks.[IMAGE END]



## Section References
[bib.bib21] Liu et al. (2024b) Yupei Liu Yuqi Jia Runpeng Geng Jinyuan Jia and Neil Zhenqiang Gong. 2024b. Formalizing and benchmarking prompt injection attacks and defenses. In 33rd USENIX Security Symposium (USENIX Security 24) pages 1831–1847.