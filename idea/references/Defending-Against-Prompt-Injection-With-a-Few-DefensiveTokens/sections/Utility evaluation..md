Utility evaluation.
We use AlpacaEval2~\cite{bib.bib16} to assess the general instruction following utility with DefensiveTokens. It compares the responses on 805 AlpacaFarm~\cite{bib.bib9} samples from the target model against those from a reference model (GPT-4 version turbo-2024-04-09) and produces a WinRate (\uparrow) indicating how often the tested model outperforms the reference model in the view of an LLM judge (gpt-4o). AlpacaEval2 ranking has a 0.98 correlation to Chatbot Arena~\cite{bib.bib7} the benchmark using human feedback. This testset AlpacaFarm is different and in another domain from Cleaned Alpaca~\cite{bib.bib34} the training dataset. Besides the official AlpacaFarm test set we also use AlpacaEval2 to evaluate utility on the SEP dataset~\cite{bib.bib54} with Llama3-8B-Instruct as reference model to assess the utility-security trade-off on SEP. We mostly use the code in ~\cite{bib.bib6}.


## Section References
[bib.bib16] Li et al. (2023) Xuechen Li Tianyi Zhang Yann Dubois Rohan Taori Ishaan Gulrajani Carlos Guestrin Percy Liang and Tatsunori B. Hashimoto. 2023. AlpacaEval: An Automatic Evaluator of Instruction-following Models. https://github.com/tatsu-lab/alpaca_eval
[bib.bib9] Dubois et al. (2023) Yann Dubois Chen Xuechen Li Rohan Taori Tianyi Zhang Ishaan Gulrajani Jimmy Ba Carlos Guestrin Percy S Liang and Tatsunori B Hashimoto. 2023. Alpacafarm: A simulation framework for methods that learn from human feedback. In Advances in Neural Information Processing Systems (NeurIPS). Article 1308 31 pages. https://dl.acm.org/doi/10.5555/3666122.3667430
[bib.bib7] Chiang et al. (2024) Wei-Lin Chiang Lianmin Zheng Ying Sheng Anastasios N. Angelopoulos Tianle Li Dacheng Li Banghua Zhu Hao Zhang Michael I. Jordan Joseph E. Gonzalez and Ion Stoica. 2024. Chatbot arena: an open platform for evaluating LLMs by human preference. In International Conference on Machine Learning (ICML). JMLR.org Article 331 30 pages. https://dl.acm.org/doi/abs/10.5555/3692070.3692401
[bib.bib34] Ruebsamen (2024) Gene Ruebsamen. 2024. Cleaned Alpaca Dataset. https://github.com/gururise/AlpacaDataCleaned
[bib.bib54] Zverev et al. (2025) Egor Zverev Sahar Abdelnabi Mario Fritz and Christoph H Lampert. 2025. Can LLMs Separate Instructions From Data? And What Do We Even Mean By That?. In International Conference on Learning Representations (ICLR). https://openreview.net/pdf?id=8EtSBX41mt
[bib.bib6] Chen et al. (2025c) Sizhe Chen Arman Zharmagambetov David Wagner and Chuan Guo. 2025c. Meta SecAlign: A Secure Foundation LLM Against Prompt Injection Attacks. arXiv:2507.02735 (2025). https://arxiv.org/abs/2507.02735