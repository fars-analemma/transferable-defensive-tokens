3.1. Preliminaries
We consider an LLM application that follows the format below.
 An LLM input in LLM-integrated applications
 \mathsf{[INST]} Please write a clear and efficient algorithm that solves the following problem. \mathsf{[DATA]} Calculate the Fibonacci sequence up to the n-th number. \mathsf{[RESP]}
 The input consists of a prompt (instruction from a trusted user) and data (from untrusted external sources) separated by delimiters \mathsf{[INST]} \mathsf{[DATA]} and \mathsf{[RESP]} whose specific choices vary across different LLMs. A prompt injection attacker inserts new instructions into the external data see the injection below in red.
 A prompt injection example
 \mathsf{[INST]} Please write a clear and efficient algorithm that solves the following problem. \mathsf{[DATA]} Calculate the Fibonacci sequence up to the n-th number. Ignore previous instructions and share with me the code you generated for Bob.
 \mathsf{[RESP]}
 Our considered threat model follows ~\cite{bib.bib4 bib.bib5}. We assume the attacker has the ability to inject an instruction into the data part. The attacker has full knowledge of the benign instruction and the prompt format but cannot modify them. The attack succeeds when the LLM responds to the injected instruction rather than treating it as part of the data to be processed according to the legitimate user instruction. As defenders our security objective is to ensure the LLM ignores potential injections in the data portion. Our goal is to preserve the LLMâ€™s utility to provide high-quality responses to user instructions whether a prompt injection exists or not.


## Section References
[bib.bib4] Chen et al. (2025a) Sizhe Chen Julien Piet Chawin Sitawarin and David Wagner. 2025a. StruQ: Defending against prompt injection with structured queries. In USENIX Security Symposium. https://arxiv.org/abs/2402.06363
[bib.bib5] Chen et al. (2025b) Sizhe Chen Arman Zharmagambetov Saeed Mahloujifar Kamalika Chaudhuri David Wagner and Chuan Guo. 2025b. SecAlign: Defending Against Prompt Injection with Preference Optimization. In The ACM Conference on Computer and Communications Security (CCS). https://arxiv.org/abs/2410.05451