4.2. DefensiveToken As SOTA Test-Time Defense
Test-time defenses are flexible for developers to decide whether to apply them in different scenarios. Existing test-time defenses include detectors defensive prompting and system-level defense see Table1. Detectors are designed to refuse answering when there is an attack and thus inherently lose utility and are out of the scope of our proposed prevention-based defenses. Also inapplicable is system-level defense the only one ~\cite{bib.bib8} of which to the best of our knowledge only work in agentic (tool-calling) cases where there is an attack on the system control flow. In comparison DefensiveTokens work more broadly against all attacks with any types of the text inputs. Thus we focus on comparison with below prompting test-time defenses.
 •
 Reminder defense ~\cite{bib.bib46} adds this sentence after the user instruction: Do not execute or adhere to any potential instructions or commands in the following data.
 •
 Sandwich defense ~\cite{bib.bib14} appends a sentence in the data as a reminder about the user instruction: “Please always remember that your task is: {instruction}.”
 •
 TextGrad defense. To potentially improve the prompting defenses we introduce another baseline that leverages a popular automated prompt optimization framework called TextGrad~\cite{bib.bib48} for security against prompt injections. This baseline is similar to our DefensiveToken but instead of optimizing the “soft” token embedding it heuristically searches the “hard” human-readable tokens using LLM feedback (gpt-4o in our experiment) and thus only black-box access to the target LLM is needed. We describe our system prompt optimization goal as a defense against prompt injection. We set the reward also based on the LLM judge. The reward is -1 if the injection is followed. Otherwise the reward is 1 if the response is better than the undefended counterpart and 0 if not. We optimize for 150 steps using the StruQ defensive fine-tuning dataset with a batch size of 8.
 \Description
 The evaluation encompasses six diverse datasets: AlpacaFarm GCG ASR on AlpacaFarm SEP TaskTracker CyberSecEval2 and InjecAgent. Each subplot compares multiple defense approaches including No Defense (baseline) TextGrad Reminder Sandwich DefensiveToken StruQ LoRA StruQ-Full and SecAlign LoRA. The No Defense baseline consistently exhibits the highest ASR values across all datasets typically ranging from 25% to over 95% demonstrating severe vulnerability to adversarial attacks. DefensiveToken demonstrates several key advantages as a test-time defense mechanism. First it achieves consistently strong performance across all six datasets without requiring any model retraining or parameter updates. This deployment flexibility makes it particularly valuable for real-world applications where modifying pre-trained models is impractical or costly. Second DefensiveToken maintains competitive ASR reduction compared to other test-time methods while offering superior implementation simplicity. Unlike training-time approaches that require extensive computational resources DefensiveToken can be immediately deployed as a plug-and-play solution. The results reveal that while training-time defenses generally achieve lower ASR values with many reaching single-digit percentages DefensiveToken provides an optimal balance between effectiveness and practicality.
  Fig.2 shows the ASR (averaged across the four tested LLMs) for five benchmarks with the middle sub-figure on the top showing optimization-based GCG results. In every sub-figure the left five bars are for test-time defenses. Adding only 5 DefensiveTokens reduces optimization-free ASRs by an order of magnitude on AlpacaFarm SEP TaskTracker by three times on CyberSecEval2 and by five times on InjecAgent. This is a significant robustness especially compared to existing flexible test-time baselines which never reduce ASRs by over two times on all benchmarks. For the strongest tested optimization-based GCG attack DefensiveToken is able to reduce average ASR by about two times. Note that GCG is performed in an adaptive manner with the attacker knowing the DefensiveTokens embeddings and doing gradient update with them for the attack goal. In such an extreme test DefensiveTokens are also effective while existing test-time alternatives almost go invalid. Model-specific numbers are present in Table4.
 We credit the success of DefensiveToken over prompting defenses to the large continuous optimization space where the embeddings could be optimized for the complex defense goal. The optimized token embeddings are far from those in the model’s original vocabulary that are available for prompting. Table2 shows the 1-norm of the embeddings in the vocabulary vs. those optimized by us. The latter is two orders of magnitude larger hinting that it is almost impossible to find tokens in the vocabulary with similar defense performance.
[TABLE START]<table>
	<tr>
		<td>Defense Type</td>
		<td>Flexibility</td>
		<td>Security</td>
		<td>Utility</td>
	</tr>
	<tr>
		<td>Training-Time ~\cite{bib.bib6}</td>
		<td>\times</td>
		<td>✓</td>
		<td>✓</td>
	</tr>
	<tr>
		<td>Prompting-Based ~\cite{bib.bib14}</td>
		<td>✓</td>
		<td>\times</td>
		<td>✓</td>
	</tr>
	<tr>
		<td>Detection-Based ~\cite{bib.bib23}</td>
		<td>✓</td>
		<td>✓</td>
		<td>\times</td>
	</tr>
	<tr>
		<td>System-Level ~\cite{bib.bib8}</td>
		<td>✓</td>
		<td>✓</td>
		<td>\times</td>
	</tr>
	<tr>
		<td>DefensiveToken</td>
		<td>✓</td>
		<td>✓</td>
		<td>✓</td>
	</tr>
</table>
Table 1. DefensiveToken and existing defenses. Training-time defenses yield robust models with limited utility loss, but are not flexible, i.e., cannot be stripped off to recover utility at test time.
Other existing defenses operate at test time but have different limitations.
Prompting-based defenses are ineffective ~\cite{bib.bib5}. Detectors are designed to refuse to output when an attack is detected. A subset of prompt injections that manipulate the system’s control flow can be stopped by system-level defense, which has noticeable utility loss. DefensiveToken offers security comparable to training-time defenses without hurting utility, and is as flexible as a test-time defense—allowing it to be deployed only when needed.[TABLE END]

[TABLE START]<table>
	<tr>
		<td>Embeddings in</td>
		<td>Avg 1-norm</td>
		<td>Max 1-norm</td>
	</tr>
	<tr>
		<td>Vocabulary Tokens</td>
		<td>34</td>
		<td>47</td>
	</tr>
	<tr>
		<td>Defensive Tokens</td>
		<td>4332</td>
		<td>4594</td>
	</tr>
</table>
Table 2. The magnitude of 4096-d embeddings in the Llama-3.1-8B-Instruct vocabulary vs. those in DefensiveToken.[TABLE END]

[TABLE START]<table>
	<tr>
		<td></td>
		<td>Benchmark</td>
		<td colspan="3">AlpacaFarm</td>
		<td colspan="2">SEP</td>
		<td>TaskTracker</td>
		<td>CyberSecEval2</td>
		<td>InjecAgent</td>
	</tr>
	<tr>
		<td></td>
		<td>Defense</td>
		<td>WinRate \uparrow</td>
		<td>ASR \downarrow</td>
		<td>GCG-ASR \downarrow</td>
		<td>WinRate \uparrow</td>
		<td>ASR \downarrow</td>
		<td>ASR \downarrow</td>
		<td>ASR \downarrow</td>
		<td>ASR \downarrow</td>
	</tr>
	<tr>
		<td rowspan="8">Llama3-8B-Instruct</td>
		<td>None</td>
		<td>26.5</td>
		<td>51.4</td>
		<td>94.7</td>
		<td>50.0</td>
		<td>79.1</td>
		<td>16.4</td>
		<td>49.1</td>
		<td>29.6</td>
	</tr>
	<tr>
		<td>TextGrad</td>
		<td>22.9</td>
		<td>0</td>
		<td>31.6</td>
		<td>1.1</td>
		<td>3.5</td>
		<td>0.25</td>
		<td>1.8</td>
		<td>8.8</td>
	</tr>
	<tr>
		<td>Reminder</td>
		<td>24.4</td>
		<td>34.6</td>
		<td>96.6</td>
		<td>48.3</td>
		<td>75.2</td>
		<td>19.8</td>
		<td>43.6</td>
		<td>42.2</td>
	</tr>
	<tr>
		<td>Sandwich</td>
		<td>26.8</td>
		<td>56.7</td>
		<td>100.0</td>
		<td>46.9</td>
		<td>63.4</td>
		<td>5.5</td>
		<td>41.8</td>
		<td>14.8</td>
	</tr>
	<tr>
		<td>DefensiveToken</td>
		<td>27.0</td>
		<td>0.5</td>
		<td>37.5</td>
		<td>51.6</td>
		<td>3.2</td>
		<td>0.27</td>
		<td>3.6</td>
		<td>2.7</td>
	</tr>
	<tr>
		<td>StruQ-LoRA</td>
		<td>28.0</td>
		<td>0</td>
		<td>4.8</td>
		<td>50.4</td>
		<td>1.5</td>
		<td>0.24</td>
		<td>7.3</td>
		<td>0</td>
	</tr>
	<tr>
		<td>StruQ-Full</td>
		<td>27.9</td>
		<td>0</td>
		<td>2.9</td>
		<td>51.2</td>
		<td>0.4</td>
		<td>0.23</td>
		<td>10.9</td>
		<td>0</td>
	</tr>
	<tr>
		<td>SecAlign-LoRA</td>
		<td>27.0</td>
		<td>0</td>
		<td>1.9</td>
		<td>47.5</td>
		<td>3.1</td>
		<td>0.18</td>
		<td>18.2</td>
		<td>0</td>
	</tr>
	<tr>
		<td rowspan="8">Llama3.1-8B-Instruct</td>
		<td>None</td>
		<td>29.1</td>
		<td>69.2</td>
		<td>96.2</td>
		<td>54.7</td>
		<td>71.4</td>
		<td>26.6</td>
		<td>16.4</td>
		<td>33.0</td>
	</tr>
	<tr>
		<td>TextGrad</td>
		<td>20.9</td>
		<td>15.9</td>
		<td>92.8</td>
		<td>36.3</td>
		<td>22.1</td>
		<td>20.3</td>
		<td>23.6</td>
		<td>25.3</td>
	</tr>
	<tr>
		<td>Reminder</td>
		<td>26.2</td>
		<td>29.8</td>
		<td>97.1</td>
		<td>52.5</td>
		<td>50.6</td>
		<td>23.3</td>
		<td>7.3</td>
		<td>34.3</td>
	</tr>
	<tr>
		<td>Sandwich</td>
		<td>29.7</td>
		<td>60.6</td>
		<td>100.0</td>
		<td>51.5</td>
		<td>55.0</td>
		<td>11.1</td>
		<td>25.5</td>
		<td>21.4</td>
	</tr>
	<tr>
		<td>DefensiveToken</td>
		<td>28.5</td>
		<td>0.5</td>
		<td>24.6</td>
		<td>53.8</td>
		<td>2.8</td>
		<td>0.19</td>
		<td>7.3</td>
		<td>0.6</td>
	</tr>
	<tr>
		<td>StruQ-LoRA</td>
		<td>27.6</td>
		<td>0.5</td>
		<td>10.1</td>
		<td>51.6</td>
		<td>1.4</td>
		<td>0.23</td>
		<td>12.7</td>
		<td>3.9</td>
	</tr>
	<tr>
		<td>StruQ-Full</td>
		<td>28.2</td>
		<td>0</td>
		<td>17.3</td>
		<td>52.9</td>
		<td>0.2</td>
		<td>0.18</td>
		<td>10.9</td>
		<td>1.8</td>
	</tr>
	<tr>
		<td>SecAlign-LoRA</td>
		<td>27.5</td>
		<td>0</td>
		<td>1.0</td>
		<td>50.5</td>
		<td>2.7</td>
		<td>0.19</td>
		<td>5.5</td>
		<td>0.1</td>
	</tr>
	<tr>
		<td rowspan="8">Falcon3-7B-Instruct</td>
		<td>None</td>
		<td>30.7</td>
		<td>84.6</td>
		<td>94.2</td>
		<td>50.5</td>
		<td>80.8</td>
		<td>27.7</td>
		<td>50.9</td>
		<td>20.3</td>
	</tr>
	<tr>
		<td>TextGrad</td>
		<td>28.0</td>
		<td>97.1</td>
		<td>70.8</td>
		<td>47.0</td>
		<td>80.6</td>
		<td>28.1</td>
		<td>29.1</td>
		<td>11.5</td>
	</tr>
	<tr>
		<td>Reminder</td>
		<td>29.8</td>
		<td>75.0</td>
		<td>99.0</td>
		<td>51.8</td>
		<td>83.4</td>
		<td>30.5</td>
		<td>47.3</td>
		<td>27.2</td>
	</tr>
	<tr>
		<td>Sandwich</td>
		<td>30.9</td>
		<td>70.7</td>
		<td>99.0</td>
		<td>49.8</td>
		<td>68.4</td>
		<td>8.9</td>
		<td>43.6</td>
		<td>3.3</td>
	</tr>
	<tr>
		<td>DefensiveToken</td>
		<td>29.2</td>
		<td>4.8</td>
		<td>59.4</td>
		<td>48.3</td>
		<td>6.7</td>
		<td>0.27</td>
		<td>12.7</td>
		<td>1.6</td>
	</tr>
	<tr>
		<td>StruQ-LoRA</td>
		<td>29.2</td>
		<td>1.0</td>
		<td>73.1</td>
		<td>45.4</td>
		<td>11.6</td>
		<td>0.27</td>
		<td>21.8</td>
		<td>0.1</td>
	</tr>
	<tr>
		<td>StruQ-Full</td>
		<td>25.3</td>
		<td>0</td>
		<td>48.8</td>
		<td>31.3</td>
		<td>2.0</td>
		<td>0.20</td>
		<td>7.3</td>
		<td>0</td>
	</tr>
	<tr>
		<td>SecAlign-LoRA</td>
		<td>27.4</td>
		<td>0.5</td>
		<td>81.7</td>
		<td>46.1</td>
		<td>35.4</td>
		<td>1.1</td>
		<td>29.1</td>
		<td>2.4</td>
	</tr>
	<tr>
		<td rowspan="8">Qwen2.5-7B-Instruct</td>
		<td>None</td>
		<td>32.7</td>
		<td>93.3</td>
		<td>95.7</td>
		<td>54.1</td>
		<td>87.1</td>
		<td>37.2</td>
		<td>45.5</td>
		<td>23.5</td>
	</tr>
	<tr>
		<td>TextGrad</td>
		<td>13.8</td>
		<td>97.6</td>
		<td>82.6</td>
		<td>36.1</td>
		<td>90.2</td>
		<td>33.7</td>
		<td>34.6</td>
		<td>19.8</td>
	</tr>
	<tr>
		<td>Reminder</td>
		<td>29.0</td>
		<td>94.7</td>
		<td>99.0</td>
		<td>50.7</td>
		<td>85.0</td>
		<td>35.3</td>
		<td>32.7</td>
		<td>29.6</td>
	</tr>
	<tr>
		<td>Sandwich</td>
		<td>32.3</td>
		<td>85.6</td>
		<td>100.0</td>
		<td>53.3</td>
		<td>70.2</td>
		<td>18.5</td>
		<td>47.3</td>
		<td>11.7</td>
	</tr>
	<tr>
		<td>DefensiveToken</td>
		<td>34.2</td>
		<td>1.0</td>
		<td>73.6</td>
		<td>50.5</td>
		<td>4.3</td>
		<td>0.25</td>
		<td>20.0</td>
		<td>15.8</td>
	</tr>
	<tr>
		<td>StruQ-LoRA</td>
		<td>33.5</td>
		<td>1.4</td>
		<td>65.4</td>
		<td>50.8</td>
		<td>3.9</td>
		<td>0.24</td>
		<td>23.6</td>
		<td>2.1</td>
	</tr>
	<tr>
		<td>StruQ-Full</td>
		<td>31.1</td>
		<td>0</td>
		<td>46.2</td>
		<td>50.5</td>
		<td>2.0</td>
		<td>0.20</td>
		<td>3.6</td>
		<td>0.5</td>
	</tr>
	<tr>
		<td>SecAlign-LoRA</td>
		<td>32.8</td>
		<td>1.9</td>
		<td>64.9</td>
		<td>50.5</td>
		<td>14.7</td>
		<td>0.57</td>
		<td>20.0</td>
		<td>5.5</td>
	</tr>
</table>
Table 4. Utility (WinRate \uparrow) and security (ASR \downarrow) of test-time (TextGrad, Reminder, Sandwich, DefensiveToken) and training-time (StruQ, SecAlign using Full/LoRA fine-tuning) defense baselines. Numbers are averaged across models in  Fig. 2 for visualization.[TABLE END]

[IMAGE START] [IMAGE URL: /mnt/bmcpfs-29000zjpjtl6xjmjiifyk/xkhu/ideation_workspace/papers/reference_figures/cbfd0b621d4454ce2ed6d2196eb2b4d1.png]  [IMAGE URL: /mnt/bmcpfs-29000zjpjtl6xjmjiifyk/xkhu/ideation_workspace/papers/reference_figures/9c308cc6f6449752e228b6460b8eea52.png]  [IMAGE URL: /mnt/bmcpfs-29000zjpjtl6xjmjiifyk/xkhu/ideation_workspace/papers/reference_figures/30278294f860e499cdf2c2620991a405.png]  [IMAGE URL: /mnt/bmcpfs-29000zjpjtl6xjmjiifyk/xkhu/ideation_workspace/papers/reference_figures/c50561b5aba1e79a65dc89a9f5bd9032.png]  [IMAGE URL: /mnt/bmcpfs-29000zjpjtl6xjmjiifyk/xkhu/ideation_workspace/papers/reference_figures/f88c802ed3f020445ca5db4c89ca530d.png]  [IMAGE URL: /mnt/bmcpfs-29000zjpjtl6xjmjiifyk/xkhu/ideation_workspace/papers/reference_figures/8ab012545a6d58d94db7c5c40fef7654.png] Figure 2. The security of DefensiveToken vs. existing test-time and training-time baselines. The values are averaged across all four tested LLMs (Llama3-8B-Instruct, Llama3.1-8B-Instruct, Falcon3-7B-Instruct, and Qwen2.5-7B-Instruct) with breakdown numbers in  Table 4. DefensiveToken is both flexible and effective.[IMAGE END]

[IMAGE START]Table 4. Utility (WinRate \uparrow) and security (ASR \downarrow) of test-time (TextGrad, Reminder, Sandwich, DefensiveToken) and training-time (StruQ, SecAlign using Full/LoRA fine-tuning) defense baselines. Numbers are averaged across models in  Fig. 2[ref_id]S4.F2 for visualization.[IMAGE END]



## Section References
[bib.bib8] Debenedetti et al. (2025) Edoardo Debenedetti Ilia Shumailov Tianqi Fan Jamie Hayes Nicholas Carlini Daniel Fabian Christoph Kern Chongyang Shi Andreas Terzis and Florian Tramèr. 2025. Defeating prompt injections by design. arXiv preprint arXiv:2503.18813 (2025). https://arxiv.org/abs/2503.18813
[bib.bib46] Yi et al. (2025) Jingwei Yi Yueqi Xie Bin Zhu Emre Kiciman Guangzhong Sun Xing Xie and Fangzhao Wu. 2025. Benchmarking and Defending against Indirect Prompt Injection Attacks on Large Language Models. In ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1 (KDD). 1809–1820. doi:10.1145/3690624.3709179 [https://doi.org/10.1145/3690624.3709179]
[bib.bib14] Learn Prompting (2023) Learn Prompting. 2023. Learn Prompting: Your guide to communicating with AI. https://learnprompting.org.
[bib.bib48] Yuksekgonul et al. (2025) Mert Yuksekgonul Federico Bianchi Joseph Boen Sheng Liu Pan Lu Zhi Huang Carlos Guestrin and James Zou. 2025. Optimizing Generative AI by Backpropagating Language Model Feedback. In Nature Vol. 639. 609–616. doi:10.1038/s41586-025-08661-4 [https://doi.org/10.1038/s41586-025-08661-4]
[bib.bib6] Chen et al. (2025c) Sizhe Chen Arman Zharmagambetov David Wagner and Chuan Guo. 2025c. Meta SecAlign: A Secure Foundation LLM Against Prompt Injection Attacks. arXiv:2507.02735 (2025). https://arxiv.org/abs/2507.02735
[bib.bib23] Meta (2024) Meta. 2024. Prompt Guard. https://llama.meta.com/docs/model-cards-and-prompt-formats/prompt-guard
[bib.bib5] Chen et al. (2025b) Sizhe Chen Arman Zharmagambetov Saeed Mahloujifar Kamalika Chaudhuri David Wagner and Chuan Guo. 2025b. SecAlign: Defending Against Prompt Injection with Preference Optimization. In The ACM Conference on Computer and Communications Security (CCS). https://arxiv.org/abs/2410.05451