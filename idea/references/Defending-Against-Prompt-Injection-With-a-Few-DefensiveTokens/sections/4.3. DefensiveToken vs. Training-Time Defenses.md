4.3. DefensiveToken vs. Training-Time Defenses
Training-time defenses without flexibility to developers enjoy strong security against prompt injections. StruQ ~\cite{bib.bib4} has near-zero attack success rates on optimization-free prompt injections. We use the StruQ loss and dataset to optimize the model using full or LoRA fine-tuning for one epoch using learning rates 4\times 10^{-6} and 1.6\times 10^{-4} respectively as recommended in ~\cite{bib.bib5}. LoRA uses hyper-parameters r=64 lora_alpha=8 lora_dropout=0.1 target_modules = ["q_proj" "v_proj"] as recommended in ~\cite{bib.bib5}. Despite altering 0.34% weights the trained LoRA adapter still needs to be merged into the original model to form a new LLM and is less flexible than test-time defenses like DefensiveToken.
 The right 3 bars on every sub-figure in Fig.2 show results of training-time defenses. Despite as a test-time defense DefensiveToken enjoys a security level comparable to training-time defenses. In the largest TaskTracker benchmark DefensiveTokens mitigates optimization-free attacks to an average ASR of 0.24% which is close to training-time defenses (ASRs 0.20% to 0.51%). A similar trend can be seen on AlpacaFarm SEP and CyberSecEval2 benchmarks. For attacks using optimization or on agentic InjecAgent benchmark DefensiveToken is slightly weaker than training-time alternatives.
 \Description
 This figure shows the trade-off between Attack Success Rate (ASR) and utility across three datasets: AlpacaFarm GCG ASR on AlpacaFarm and SEP. The plots position each defense method based on its ASR (x-axis lower is better) and utility measured by win rate (y-axis higher is better) allowing for assessment of both security and performance. The ideal defense methods appear in the top-left region of each plot representing low ASR with high utility. Across all three datasets DefensiveToken (ours) consistently achieves this optimal positioning compared to other approaches. A key strength of DefensiveToken is its ability to maintain high utility while providing strong defense. Unlike some methods that achieve low ASR at the cost of significantly reduced utility DefensiveToken preserves the model’s performance making it a practical solution for real-world deployment where both security and functionality are critical.
[IMAGE START] [IMAGE URL: /mnt/bmcpfs-29000zjpjtl6xjmjiifyk/xkhu/ideation_workspace/papers/reference_figures/cbfd0b621d4454ce2ed6d2196eb2b4d1.png]  [IMAGE URL: /mnt/bmcpfs-29000zjpjtl6xjmjiifyk/xkhu/ideation_workspace/papers/reference_figures/9c308cc6f6449752e228b6460b8eea52.png]  [IMAGE URL: /mnt/bmcpfs-29000zjpjtl6xjmjiifyk/xkhu/ideation_workspace/papers/reference_figures/30278294f860e499cdf2c2620991a405.png]  [IMAGE URL: /mnt/bmcpfs-29000zjpjtl6xjmjiifyk/xkhu/ideation_workspace/papers/reference_figures/c50561b5aba1e79a65dc89a9f5bd9032.png]  [IMAGE URL: /mnt/bmcpfs-29000zjpjtl6xjmjiifyk/xkhu/ideation_workspace/papers/reference_figures/f88c802ed3f020445ca5db4c89ca530d.png]  [IMAGE URL: /mnt/bmcpfs-29000zjpjtl6xjmjiifyk/xkhu/ideation_workspace/papers/reference_figures/8ab012545a6d58d94db7c5c40fef7654.png] Figure 2. The security of DefensiveToken vs. existing test-time and training-time baselines. The values are averaged across all four tested LLMs (Llama3-8B-Instruct, Llama3.1-8B-Instruct, Falcon3-7B-Instruct, and Qwen2.5-7B-Instruct) with breakdown numbers in  Table 4. DefensiveToken is both flexible and effective.[IMAGE END]

[IMAGE START]Table 4. Utility (WinRate \uparrow) and security (ASR \downarrow) of test-time (TextGrad, Reminder, Sandwich, DefensiveToken) and training-time (StruQ, SecAlign using Full/LoRA fine-tuning) defense baselines. Numbers are averaged across models in  Fig. 2[ref_id]S4.F2 for visualization.[IMAGE END]



## Section References
[bib.bib4] Chen et al. (2025a) Sizhe Chen Julien Piet Chawin Sitawarin and David Wagner. 2025a. StruQ: Defending against prompt injection with structured queries. In USENIX Security Symposium. https://arxiv.org/abs/2402.06363
[bib.bib5] Chen et al. (2025b) Sizhe Chen Arman Zharmagambetov Saeed Mahloujifar Kamalika Chaudhuri David Wagner and Chuan Guo. 2025b. SecAlign: Defending Against Prompt Injection with Preference Optimization. In The ACM Conference on Computer and Communications Security (CCS). https://arxiv.org/abs/2410.05451