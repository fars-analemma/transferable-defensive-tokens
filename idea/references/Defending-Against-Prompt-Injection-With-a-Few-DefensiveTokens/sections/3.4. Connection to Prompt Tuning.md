3.4. Connection to Prompt Tuning
Our defense can be viewed as an instance of prompt tuning~\cite{bib.bib15} which prepends a few optimizable token embeddings to the input. Traditionally prompt tuning has been shown to be effective in improving the utility for a given task instruction.
 Input in (traditional) prompt tuning for utility
 [tokens with trainable embeddings] \mathsf{[INST]} [task instruction (same across samples)] \mathsf{[DATA]} [data on this task (different across samples)] \mathsf{[RESP]}
 We extend traditional prompt tuning to achieve a more complex goal: preserving utility while achieving security against prompt injections on different instructions. See below for what is new in DefensiveToken.
 Input in DefensiveToken tuning for security
 [tokens with trainable embeddings] \mathsf{[INST]} [instruction to be followed (different across samples)] \mathsf{[DATA]} [data on this task (different across samples) which may contain injections that should be ignored] \mathsf{[RESP]}
 Despite optimizing for this new security objective on multiple tasks we find that the optimization of prepended embeddings is still effective. By optimizing those \sim20k float-point variables DefensiveToken effectively mitigates prompt injection with a minimal utility drop without changing the LLM parameters.


## Section References
[bib.bib15] Lester et al. (2021) Brian Lester Rami Al-Rfou and Noah Constant. 2021. The Power of Scale for Parameter-Efficient Prompt Tuning. In Empirical Methods in Natural Language Processing (EMNLP) Marie-Francine Moens Xuanjing Huang Lucia Specia and Scott Wen-tau Yih (Eds.). 3045â€“3059. doi:10.18653/v1/2021.emnlp-main.243 [https://doi.org/10.18653/v1/2021.emnlp-main.243]