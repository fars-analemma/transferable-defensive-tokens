% DRIP-Defending-Prompt-Injection-via-Token-wise-Representation-Editing-and-Residual-Instruction-Fusion
@Inproceedings{Liu2025DRIPDP,
 author = {Ruofan Liu and Yun Lin and Zhiyong Huang and J. Dong},
 title = {DRIP: Defending Prompt Injection via Token-wise Representation Editing and Residual Instruction Fusion},
 year = {2025}
}

% StruQ-Defending-Against-Prompt-Injection-with-Structured-Queries
@misc{struqdefendingagainstunknown,
  title={StruQ: Defending Against Prompt Injection with Structured Queries},
  author={Sizhe Chen, Julien Piet, Chawin Sitawarin, David Wagner},
  url={https://www.usenix.org/system/files/usenixsecurity25-chen-sizhe.pdf},
  note={Synthesized BibTeX entry}
}

% Attention-Tracker-Detecting-Prompt-Injection-Attacks-in-LLMs
@Article{Hung2024AttentionTD,
 author = {Kuo-Han Hung and Ching-Yun Ko and Ambrish Rawat and I-Hsin Chung and Winston H. Hsu and Pin-Yu Chen},
 booktitle = {North American Chapter of the Association for Computational Linguistics},
 pages = {2309-2322},
 title = {Attention Tracker: Detecting Prompt Injection Attacks in LLMs},
 year = {2024}
}

% Defending-Against-Prompt-Injection-With-a-Few-DefensiveTokens
@misc{chen2025defendingpromptinjectiondefensivetokens,
      title={Defending Against Prompt Injection With a Few DefensiveTokens}, 
      author={Sizhe Chen and Yizhu Wang and Nicholas Carlini and Chawin Sitawarin and David Wagner},
      year={2025},
      eprint={2507.07974},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2507.07974}, 
}


% SecAlign: Defending Against Prompt Injection with Preference Optimization
@Article{Chen2024SecAlignDA,
 author = {Sizhe Chen and Arman Zharmagambetov and Saeed Mahloujifar and Kamalika Chaudhuri and Chuan Guo},
 booktitle = {Conference on Computer and Communications Security},
 journal = {Proceedings of the 2025 ACM SIGSAC Conference on Computer and Communications Security},
 title = {SecAlign: Defending Against Prompt Injection with Preference Optimization},
 year = {2024}
}


% Meta SecAlign: A Secure Foundation LLM Against Prompt Injection Attacks
@Article{Chen2025MetaSA,
 author = {Sizhe Chen and Arman Zharmagambetov and David Wagner and Chuan Guo},
 booktitle = {arXiv.org},
 journal = {ArXiv},
 title = {Meta SecAlign: A Secure Foundation LLM Against Prompt Injection Attacks},
 volume = {abs/2507.02735},
 year = {2025}
}


% Zero-Shot Continuous Prompt Transfer: Generalizing Task Semantics Across Language Models
@Article{Wu2023ZeroShotCP,
 author = {Zijun Wu and Yongkang Wu and Lili Mou},
 booktitle = {International Conference on Learning Representations},
 journal = {ArXiv},
 title = {Zero-Shot Continuous Prompt Transfer: Generalizing Task Semantics Across Language Models},
 volume = {abs/2310.01691},
 year = {2023}
}


% On Transferability of Prompt Tuning for Natural Language Processing
@Article{Su2021OnTO,
 author = {Yusheng Su and Xiaozhi Wang and Yujia Qin and Chi-Min Chan and Yankai Lin and Huadong Wang and Kaiyue Wen and Zhiyuan Liu and Peng Li and Juanzi Li and Lei Hou and Maosong Sun and Jie Zhou},
 booktitle = {North American Chapter of the Association for Computational Linguistics},
 pages = {3949-3969},
 title = {On Transferability of Prompt Tuning for Natural Language Processing},
 year = {2021}
}


% Universal and Transferable Adversarial Attacks on Aligned Language Models
@Article{Zou2023UniversalAT,
 author = {Andy Zou and Zifan Wang and J. Z. Kolter and Matt Fredrikson},
 booktitle = {arXiv.org},
 journal = {ArXiv},
 title = {Universal and Transferable Adversarial Attacks on Aligned Language Models},
 volume = {abs/2307.15043},
 year = {2023}
}


% AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback
@Article{Dubois2023AlpacaFarmAS,
 author = {Yann Dubois and Xuechen Li and Rohan Taori and Tianyi Zhang and Ishaan Gulrajani and Jimmy Ba and Carlos Guestrin and Percy Liang and Tatsunori Hashimoto},
 booktitle = {Neural Information Processing Systems},
 journal = {ArXiv},
 title = {AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback},
 volume = {abs/2305.14387},
 year = {2023}
}


% Ignore Previous Prompt: Attack Techniques For Language Models
@Article{Perez2022IgnorePP,
 author = {Fábio Perez and Ian Ribeiro},
 booktitle = {arXiv.org},
 journal = {ArXiv},
 title = {Ignore Previous Prompt: Attack Techniques For Language Models},
 volume = {abs/2211.09527},
 year = {2022}
}


% Not What You've Signed Up For: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection
@Book{Greshake2023NotWY,
 author = {Kai Greshake and Sahar Abdelnabi and Shailesh Mishra and C. Endres and Thorsten Holz and Mario Fritz},
 booktitle = {AISec@CCS},
 journal = {Proceedings of the 16th ACM Workshop on Artificial Intelligence and Security},
 title = {Not What You've Signed Up For: Compromising Real-World LLM-Integrated Applications with Indirect Prompt Injection},
 year = {2023}
}


% SPoT: Better Frozen Model Adaptation through Soft Prompt Transfer
@Article{Vu2021SPoTBF,
 author = {Tu Vu and Brian Lester and Noah Constant and Rami Al-Rfou and Daniel Matthew Cer},
 booktitle = {Annual Meeting of the Association for Computational Linguistics},
 journal = {ArXiv},
 title = {SPoT: Better Frozen Model Adaptation through Soft Prompt Transfer},
 volume = {abs/2110.07904},
 year = {2021}
}


% Soft Begging: Modular and Efficient Shielding of LLMs against Prompt Injection and Jailbreaking based on Prompt Tuning
@Article{Ostermann2024SoftBM,
 author = {Simon Ostermann and Kevin Baum and Christoph Endres and Julia Masloh and P. Schramowski},
 booktitle = {arXiv.org},
 journal = {ArXiv},
 title = {Soft Begging: Modular and Efficient Shielding of LLMs against Prompt Injection and Jailbreaking based on Prompt Tuning},
 volume = {abs/2407.03391},
 year = {2024}
}


% Defending Against Indirect Prompt Injection Attacks With Spotlighting
@Article{Hines2024DefendingAI,
 author = {Keegan Hines and Gary Lopez and Matthew Hall and Federico Zarfati and Yonatan Zunger and Emre Kiciman},
 booktitle = {CAMLIS},
 journal = {ArXiv},
 title = {Defending Against Indirect Prompt Injection Attacks With Spotlighting},
 volume = {abs/2403.14720},
 year = {2024}
}


% The Power of Scale for Parameter-Efficient Prompt Tuning
@Article{Lester2021ThePO,
 author = {Brian Lester and Rami Al-Rfou and Noah Constant},
 booktitle = {Conference on Empirical Methods in Natural Language Processing},
 pages = {3045-3059},
 title = {The Power of Scale for Parameter-Efficient Prompt Tuning},
 year = {2021}
}


% Benchmarking and Defending against Indirect Prompt Injection Attacks on Large Language Models
@Article{Yi2023BenchmarkingAD,
 author = {Jingwei Yi and Yueqi Xie and Bin Zhu and Keegan Hines and Emre Kiciman and Guangzhong Sun and Xing Xie and Fangzhao Wu},
 booktitle = {Knowledge Discovery and Data Mining},
 journal = {Proceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery and Data Mining V.1},
 title = {Benchmarking and Defending against Indirect Prompt Injection Attacks on Large Language Models},
 year = {2023}
}


% The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions
@Article{Wallace2024TheIH,
 author = {Eric Wallace and Kai Xiao and R. Leike and Lilian Weng and Johannes Heidecke and Alex Beutel},
 booktitle = {arXiv.org},
 journal = {ArXiv},
 title = {The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions},
 volume = {abs/2404.13208},
 year = {2024}
}


% LoRA: Low-Rank Adaptation of Large Language Models
@Article{Hu2021LoRALA,
 author = {Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Weizhu Chen},
 booktitle = {International Conference on Learning Representations},
 journal = {ArXiv},
 title = {LoRA: Low-Rank Adaptation of Large Language Models},
 volume = {abs/2106.09685},
 year = {2021}
}


% The Llama 3 Herd of Models
@Inproceedings{Dubey2024TheL3,
 author = {Abhimanyu Dubey and others},
 title = {The Llama 3 Herd of Models},
 year = {2024}
}


% Defeating Prompt Injections by Design
@Article{Debenedetti2025DefeatingPI,
 author = {Edoardo Debenedetti and Ilia Shumailov and Tianqi Fan and Jamie Hayes and Nicholas Carlini and Daniel Fabian and Christoph Kern and Chongyang Shi and Andreas Terzis and F. Tramèr},
 booktitle = {arXiv.org},
 journal = {ArXiv},
 title = {Defeating Prompt Injections by Design},
 volume = {abs/2503.18813},
 year = {2025}
}


% Cross-Lingual Alignment of Contextual Word Embeddings, with Applications to Zero-shot Dependency Parsing
@Article{Schuster2019CrossLingualAO,
 author = {Tal Schuster and Ori Ram and R. Barzilay and A. Globerson},
 booktitle = {North American Chapter of the Association for Computational Linguistics},
 pages = {1599-1613},
 title = {Cross-Lingual Alignment of Contextual Word Embeddings, with Applications to Zero-shot Dependency Parsing},
 year = {2019}
}


% Bridging Large Gaps in Neural Network Representations with Model Stitching
@misc{bridginglargegapsunknown,
  title={Bridging Large Gaps in Neural Network Representations with Model Stitching},
  author={Neil Traft, Nick Cheney},
  url={https://openreview.net/pdf/85d234c8a7ace112fb50dd4dbac6cabe6b7fc38a.pdf},
  note={Synthesized BibTeX entry}
}


% Prefix-Tuning: Optimizing Continuous Prompts for Generation
@Article{Li2021PrefixTuningOC,
 author = {Xiang Lisa Li and Percy Liang},
 booktitle = {Annual Meeting of the Association for Computational Linguistics},
 journal = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
 pages = {4582-4597},
 title = {Prefix-Tuning: Optimizing Continuous Prompts for Generation},
 year = {2021}
}
