\section{Related Work}
\label{sec:related}

\paragraph{Prompt Injection Defenses.}
Prompt injection attacks, where adversarial instructions embedded in external data hijack LLM behavior, pose a critical threat to LLM-integrated applications~\citep{Greshake2023NotWY, Perez2022IgnorePP}. Defense strategies span multiple categories. Detection-based approaches identify malicious inputs through attention pattern analysis~\citep{Hung2024AttentionTD} or classifier-based filtering~\citep{Yi2023BenchmarkingAD}. Prevention-based methods modify input formatting through techniques like spotlighting~\citep{Hines2024DefendingAI} or structured queries~\citep{struqdefendingagainstunknown}. Training-time defenses align models to prioritize system instructions via instruction hierarchy training~\citep{Wallace2024TheIH} or preference optimization~\citep{Chen2024SecAlignDA, Chen2025MetaSA}. Soft prompt approaches train continuous tokens to enhance robustness, including DefensiveTokens~\citep{chen2025defendingpromptinjectiondefensivetokens} and Soft Begging~\citep{Ostermann2024SoftBM}. While effective, these soft prompt defenses require expensive per-model training, motivating our transfer approach.

\paragraph{Soft Prompt Transfer.}
Soft prompts, or continuous prompt embeddings, have emerged as parameter-efficient alternatives to full fine-tuning~\citep{Lester2021ThePO, Li2021PrefixTuningOC}. Research on soft prompt transferability has explored cross-task transfer through source prompt selection~\citep{Vu2021SPoTBF} and analyzed factors affecting transfer success across models and tasks~\citep{Su2021OnTO}. Recent work on zero-shot continuous prompt transfer~\citep{Wu2023ZeroShotCP} demonstrates that task semantics can generalize across language models through embedding space mapping. However, these methods focus on task-specific prompts rather than security-critical defenses, where preserving specific properties like high-norm embeddings is essential.

\paragraph{Embedding Space Alignment.}
Cross-lingual embedding alignment provides foundational techniques for mapping between representation spaces. Orthogonal Procrustes methods learn rotation matrices that align embedding spaces while preserving geometric properties~\citep{Schuster2019CrossLingualAO}. Model stitching extends these ideas to connect neural network representations across architectures~\citep{bridginglargegapsunknown}. Our work applies Orthogonal Procrustes alignment to the novel setting of security-focused soft prompt transfer, leveraging its norm-preserving property to maintain defense effectiveness across models.
